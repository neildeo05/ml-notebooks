{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training deep neural networks on gpu if you have a gpu but if you dont then on cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download dataset, but i already have it downloaded\n",
    "dataset = MNIST(root='data/', train=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation set\n",
    "\n",
    "def split_indices(n, val_pct):\n",
    "    pct_gone = int(n*val_pct)\n",
    "    print(pct_gone)\n",
    "    idxs = np.random.permutation(n)\n",
    "    #so from 12,000 images to the end - we set the training dataset to those random permutations\n",
    "    return idxs[pct_gone:], idxs[:pct_gone]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    }
   ],
   "source": [
    "train_indices, val_indices = split_indices(len(dataset), 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1294eefd0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will randomize the position of the data, in order to lessen the biases\n",
    "#we will create batches out of the indices that are specified below\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "train_loader = DataLoader(dataset, 100, sampler=train_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will create batches out of the indices that are specified below\n",
    "#it will do a random shuffle opf the data, gradient descent works better when you randomize the data\n",
    "\n",
    "#we need a validation set to test the model on data that it hasn't seen, and then you can tweak the hyperparams\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "val_loader = DataLoader(dataset, 100, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn.Linear takes inputs and outputs, creates weights and biases, bases of linear and logistic regression\n",
    "#you need to flatten it out to a vector of size 784\n",
    "#the outputs are the probabilites of the numbers being the correct prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, in the deep learning neural network we are creating: \n",
    "    #we will use 2 nn.Linear objects. Each one acts as a hidden layer inside the model\n",
    "    #the first layer, nn.Linear, wil transform the input matrix, which has already been reshaped to batch * 784\n",
    "        #to now it will be batch * hidden_size, which hidden_size is a preconfigured parameter, like 32 or 64\n",
    "        \n",
    "    #the intermediate outputs of the layer are passed on to the activation function, which operates on individual\n",
    "    #elements of the output vector\n",
    "    \n",
    "    #The result of the activation function is then passed on to the second layer:\n",
    "        #The second layer transforms the output into batch_size * 10, identical to the logistic regression model\n",
    "        \n",
    "#differences between this and logistic regression:\n",
    "    #logistic regression model takes in an image, and uses something called cross_entropy to caclulate the loss\n",
    "    #which is then put back into the model in order to optimize the function. The forward function, which is re\n",
    "    #-sponsible for outputting the alterations it does to the inputs in order for the data to be used to calc-\n",
    "    #-ulate the gradients, reshapes the data into -1,784 (-1 is kinda a placeholder), and then it returns the \n",
    "    #nn.linear model with the correct input and output layer\n",
    "    #cross entropy does its own softmax in order to convert it into probabilities\n",
    "    \n",
    "\n",
    "    #just like how linear regression and logistic regression are similar, because logistic regression is predic-\n",
    "    #-ting the probability of a certain item being the correct answer \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying out with logistic regression\n",
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(28*28,10)\n",
    "    def forward(self, xb):\n",
    "        xb = xb.reshape(-1, 784)\n",
    "        out = self.linear(xb)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MnistModel(\n",
      "  (linear): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n",
      "tensor([-0.0337,  0.0618, -0.1159,  0.0759, -0.2140, -0.1245,  0.1330, -0.0976,\n",
      "        -0.0333, -0.0070])\n"
     ]
    }
   ],
   "source": [
    "model = MnistModel()\n",
    "loss_fn = F.cross_entropy\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_on_batch(loss_fn, model, xb, yb, opt):\n",
    "    outputs = model(xb)\n",
    "    loss = loss_fn(outputs, yb)\n",
    "    \n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    \n",
    "def train(epochs, loss_fn, model,train_dl, lr):\n",
    "    opt = torch.optim.SGD(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in train_dl:\n",
    "            loss_on_batch(loss_fn, model, xb, yb, opt)\n",
    "\n",
    "    \n",
    "train(5, loss_fn, model, train_loader, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    probs, preds = torch.max(outputs, dim=1)\n",
    "    return torch.sum(preds == labels).item()/len(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0565)\n",
      "tensor(1.1911)\n",
      "tensor(1.0553)\n",
      "tensor(1.2162)\n",
      "tensor(1.0758)\n",
      "tensor(1.1116)\n",
      "tensor(1.0498)\n",
      "tensor(1.0448)\n",
      "tensor(1.1185)\n",
      "tensor(1.2097)\n",
      "tensor(1.1178)\n",
      "tensor(1.0922)\n",
      "tensor(1.1002)\n",
      "tensor(1.1426)\n",
      "tensor(1.1604)\n",
      "tensor(1.1539)\n",
      "tensor(1.1264)\n",
      "tensor(1.0968)\n",
      "tensor(1.0550)\n",
      "tensor(1.1646)\n",
      "tensor(1.1553)\n",
      "tensor(1.0921)\n",
      "tensor(1.0703)\n",
      "tensor(1.0936)\n",
      "tensor(1.1168)\n",
      "tensor(1.2248)\n",
      "tensor(1.0374)\n",
      "tensor(1.1744)\n",
      "tensor(1.0870)\n",
      "tensor(1.1043)\n",
      "tensor(1.1106)\n",
      "tensor(1.2056)\n",
      "tensor(1.1185)\n",
      "tensor(1.0827)\n",
      "tensor(1.1219)\n",
      "tensor(1.0254)\n",
      "tensor(1.1282)\n",
      "tensor(1.0727)\n",
      "tensor(1.1289)\n",
      "tensor(1.1198)\n",
      "tensor(1.2586)\n",
      "tensor(1.0964)\n",
      "tensor(1.0724)\n",
      "tensor(1.1113)\n",
      "tensor(1.0212)\n",
      "tensor(1.0960)\n",
      "tensor(1.1880)\n",
      "tensor(1.0619)\n",
      "tensor(1.1882)\n",
      "tensor(1.1134)\n",
      "tensor(1.1133)\n",
      "tensor(1.1034)\n",
      "tensor(1.1018)\n",
      "tensor(1.0560)\n",
      "tensor(1.1374)\n",
      "tensor(1.2566)\n",
      "tensor(1.0545)\n",
      "tensor(1.1186)\n",
      "tensor(1.1745)\n",
      "tensor(1.1102)\n",
      "tensor(1.1099)\n",
      "tensor(1.1614)\n",
      "tensor(1.1547)\n",
      "tensor(1.0650)\n",
      "tensor(1.1954)\n",
      "tensor(1.1618)\n",
      "tensor(1.0722)\n",
      "tensor(1.0068)\n",
      "tensor(1.0919)\n",
      "tensor(1.1619)\n",
      "tensor(1.1473)\n",
      "tensor(1.1077)\n",
      "tensor(1.0614)\n",
      "tensor(1.0721)\n",
      "tensor(1.1021)\n",
      "tensor(1.0324)\n",
      "tensor(1.1289)\n",
      "tensor(1.1035)\n",
      "tensor(1.1084)\n",
      "tensor(1.1548)\n",
      "tensor(1.1599)\n",
      "tensor(1.2262)\n",
      "tensor(1.2063)\n",
      "tensor(1.1552)\n",
      "tensor(1.1416)\n",
      "tensor(1.0400)\n",
      "tensor(1.1608)\n",
      "tensor(1.1773)\n",
      "tensor(1.0713)\n",
      "tensor(1.1056)\n",
      "tensor(1.2185)\n",
      "tensor(1.0965)\n",
      "tensor(1.1454)\n",
      "tensor(1.0740)\n",
      "tensor(1.0846)\n",
      "tensor(1.1666)\n",
      "tensor(0.9924)\n",
      "tensor(1.0695)\n",
      "tensor(1.0599)\n",
      "tensor(1.0405)\n",
      "tensor(1.2463)\n",
      "tensor(1.1030)\n",
      "tensor(1.2193)\n",
      "tensor(1.1177)\n",
      "tensor(1.0688)\n",
      "tensor(1.0900)\n",
      "tensor(1.0916)\n",
      "tensor(1.0985)\n",
      "tensor(1.1390)\n",
      "tensor(1.0888)\n",
      "tensor(1.1356)\n",
      "tensor(1.1235)\n",
      "tensor(1.1232)\n",
      "tensor(1.0685)\n",
      "tensor(1.1257)\n",
      "tensor(1.0960)\n",
      "tensor(1.1220)\n",
      "tensor(1.0672)\n",
      "tensor(1.0252)\n",
      "tensor(1.1660)\n",
      "0.8033333333333335\n"
     ]
    }
   ],
   "source": [
    "avg_acc = []\n",
    "def validate(valid_dl, model):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for xb, yb in valid_dl:\n",
    "            preds = model(xb)\n",
    "            print(loss_fn(preds, yb))\n",
    "            avg_acc.append(accuracy(preds,yb))\n",
    "\n",
    "    return sum(avg_acc)/len(avg_acc)\n",
    "\n",
    "#after running the model through the validation dataset, this was the average accuracy\n",
    "print(validate(val_loader, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MNIST(root = 'data/', train = False, transform = ToTensor())\n",
    "def predict_image(img, model):\n",
    "    xb = img.unsqueeze(0)\n",
    "    yb = model(xb)\n",
    "    prob, preds = torch.max(yb, dim = 1 )\n",
    "    \n",
    "    print(preds[0].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model predicted :\n",
      "4\n",
      "and the correct image is:\n",
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"the model predicted :\")\n",
    "x = 1111\n",
    "predict_image(test_dataset[x][0], model)\n",
    "ten, lab = test_dataset[x]\n",
    "print(\"and the correct image is:\")\n",
    "plt.imshow(ten[0],cmap='gray')\n",
    "print(lab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
