{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear regression is a supervised regression model, but logistic regression is a supervised classification model\n",
    "#predicting the value of a certain image - classifying it based on training data\n",
    "\n",
    "import torch\n",
    "#The torchvision package consists of popular datasets, model architectures, and common image transformations \n",
    "#for computer vision.\n",
    "import torchvision\n",
    "#import the MNIST dataset, which has all of the images - very popular, like the iris dataset\n",
    "from torchvision.datasets import MNIST\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actually download the dataset inside the data directory\n",
    "dataset = MNIST(root='data/', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look in your ml-notebooks directory - there is a directory called data. This is where we will store all of \n",
    "#the datasets that need separate files. The linear regression model was trained on very small amounts of data\n",
    "#and they were both tensors, so its easier to just store the data locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "#The dataset has 60,000 images! We will have an ample amount of training data\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "#this dows not need to be download\n",
    "test = MNIST(root='data/', train=False)\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<PIL.Image.Image image mode=L size=28x28 at 0x12ABE60B8>, 5)\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAOEUlEQVR4nO3dcYwV5bnH8d8jLUalENSIG9Ha22Bym0YXQUJiU6lNG4sm0JhWiHFp2mRJLAk1jam2q5DUGxujNGoicaukWLlCFS3Y1EsNS/TemDSuSBVLW6mhdMuGFTWyxEQqPPePHZoVd95Zzpk5c+D5fpLNOWeenTOPx/0xc847c15zdwE49Z1WdwMAWoOwA0EQdiAIwg4EQdiBID7Vyo2ZGR/9AxVzdxtreVN7djO7xsz+Yma7zey2Zp4LQLWs0XF2M5sg6a+SviZpQNLLkha7+58S67BnBypWxZ59jqTd7v6Wux+WtF7SgiaeD0CFmgn7BZL+MerxQLbsY8ys28z6zay/iW0BaFIzH9CNdajwicN0d++V1CtxGA/UqZk9+4CkC0c9ni5pX3PtAKhKM2F/WdIMM/ucmU2UtEjS5nLaAlC2hg/j3f0jM1smaYukCZLWuPsbpXUGoFQND701tDHeswOVq+SkGgAnD8IOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgmjplM049cyaNStZX7ZsWW6tq6srue5jjz2WrD/44IPJ+vbt25P1aNizA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQzOKKpM7OzmS9r68vWZ88eXKZ7XzM+++/n6yfc845lW27neXN4trUSTVmtkfSsKQjkj5y99nNPB+A6pRxBt1X3P1ACc8DoEK8ZweCaDbsLun3ZvaKmXWP9Qtm1m1m/WbW3+S2ADSh2cP4K919n5mdJ+l5M/uzu784+hfcvVdSr8QHdECdmtqzu/u+7HZI0jOS5pTRFIDyNRx2MzvLzD5z7L6kr0vaWVZjAMrVzGH8NEnPmNmx5/lvd/+fUrpCy8yZkz4Y27hxY7I+ZcqUZD11Hsfw8HBy3cOHDyfrRePoc+fOza0VXetetO2TUcNhd/e3JF1WYi8AKsTQGxAEYQeCIOxAEIQdCIKwA0Fwiesp4Mwzz8ytXX755cl1H3/88WR9+vTpyXo29Jor9fdVNPx1zz33JOvr169P1lO99fT0JNe9++67k/V2lneJK3t2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCKZtPAQ8//HBubfHixS3s5MQUnQMwadKkZP2FF15I1ufNm5dbu/TSS5PrnorYswNBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIyznwRmzZqVrF977bW5taLrzYsUjWU/++yzyfq9996bW9u3b19y3VdffTVZf++995L1q6++OrfW7OtyMmLPDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANB8L3xbaCzszNZ7+vrS9YnT57c8Lafe+65ZL3oevirrroqWU9dN/7II48k13377beT9SJHjhzJrX3wwQfJdYv+u4q+875ODX9vvJmtMbMhM9s5atnZZva8mb2Z3U4ts1kA5RvPYfwvJV1z3LLbJG119xmStmaPAbSxwrC7+4uS3j1u8QJJa7P7ayUtLLkvACVr9Nz4ae4+KEnuPmhm5+X9opl1S+pucDsASlL5hTDu3iupV+IDOqBOjQ697TezDknKbofKawlAFRoN+2ZJS7L7SyRtKqcdAFUpHGc3syckzZN0rqT9klZI+o2kX0u6SNJeSd9y9+M/xBvruUIexl9yySXJ+ooVK5L1RYsWJesHDhzIrQ0ODibXveuuu5L1p556KllvZ6lx9qK/+w0bNiTrN954Y0M9tULeOHvhe3Z3zzur4qtNdQSgpThdFgiCsANBEHYgCMIOBEHYgSD4KukSnH766cl66uuUJWn+/PnJ+vDwcLLe1dWVW+vv70+ue8YZZyTrUV100UV1t1A69uxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EATj7CWYOXNmsl40jl5kwYIFyXrRtMqAxJ4dCIOwA0EQdiAIwg4EQdiBIAg7EARhB4JgnL0Eq1atStbNxvxm338rGidnHL0xp52Wvy87evRoCztpD+zZgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIxtnH6brrrsutdXZ2Jtctmh548+bNDfWEtNRYetH/kx07dpTdTu0K9+xmtsbMhsxs56hlK83sn2a2I/tp7tsZAFRuPIfxv5R0zRjLf+7undnP78ptC0DZCsPu7i9KercFvQCoUDMf0C0zs9eyw/ypeb9kZt1m1m9m6UnHAFSq0bCvlvR5SZ2SBiXdl/eL7t7r7rPdfXaD2wJQgobC7u773f2Iux+V9AtJc8ptC0DZGgq7mXWMevhNSTvzfhdAeygcZzezJyTNk3SumQ1IWiFpnpl1SnJJeyQtrbDHtpCax3zixInJdYeGhpL1DRs2NNTTqa5o3vuVK1c2/Nx9fX3J+u23397wc7erwrC7++IxFj9aQS8AKsTpskAQhB0IgrADQRB2IAjCDgTBJa4t8OGHHybrg4ODLeqkvRQNrfX09CTrt956a7I+MDCQW7vvvtyTPiVJhw4dStZPRuzZgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIxtlbIPJXRae+ZrtonPyGG25I1jdt2pSsX3/99cl6NOzZgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIxtnHycwaqknSwoULk/Xly5c31FM7uOWWW5L1O+64I7c2ZcqU5Lrr1q1L1ru6upJ1fBx7diAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgnH2cXL3hmqSdP755yfrDzzwQLK+Zs2aZP2dd97Jrc2dOze57k033ZSsX3bZZcn69OnTk/W9e/fm1rZs2ZJc96GHHkrWcWIK9+xmdqGZbTOzXWb2hpktz5afbWbPm9mb2e3U6tsF0KjxHMZ/JOmH7v6fkuZK+r6ZfUHSbZK2uvsMSVuzxwDaVGHY3X3Q3bdn94cl7ZJ0gaQFktZmv7ZWUvqcUAC1OqH37GZ2saSZkv4gaZq7D0oj/yCY2Xk563RL6m6uTQDNGnfYzWySpI2SfuDuB4su/jjG3Xsl9WbPkf4kC0BlxjX0Zmaf1kjQ17n709ni/WbWkdU7JA1V0yKAMhTu2W1kF/6opF3uvmpUabOkJZJ+lt2mv9c3sAkTJiTrN998c7Je9JXIBw8ezK3NmDEjuW6zXnrppWR927ZtubU777yz7HaQMJ7D+Csl3STpdTPbkS37sUZC/msz+56kvZK+VU2LAMpQGHZ3/z9JeW/Qv1puOwCqwumyQBCEHQiCsANBEHYgCMIOBGFFl2eWurGT+Ay61KWcTz75ZHLdK664oqltF52t2Mz/w9TlsZK0fv36ZP1k/hrsU5W7j/kHw54dCIKwA0EQdiAIwg4EQdiBIAg7EARhB4JgnL0EHR0dyfrSpUuT9Z6enmS9mXH2+++/P7nu6tWrk/Xdu3cn62g/jLMDwRF2IAjCDgRB2IEgCDsQBGEHgiDsQBCMswOnGMbZgeAIOxAEYQeCIOxAEIQdCIKwA0EQdiCIwrCb2YVmts3MdpnZG2a2PFu+0sz+aWY7sp/51bcLoFGFJ9WYWYekDnffbmafkfSKpIWSvi3pkLvfO+6NcVINULm8k2rGMz/7oKTB7P6wme2SdEG57QGo2gm9ZzeziyXNlPSHbNEyM3vNzNaY2dScdbrNrN/M+pvqFEBTxn1uvJlNkvSCpP9y96fNbJqkA5Jc0k81cqj/3YLn4DAeqFjeYfy4wm5mn5b0W0lb3H3VGPWLJf3W3b9Y8DyEHahYwxfC2MhXmz4qadfooGcf3B3zTUk7m20SQHXG82n8lyT9r6TXJR3NFv9Y0mJJnRo5jN8jaWn2YV7qudizAxVr6jC+LIQdqB7XswPBEXYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Io/MLJkh2Q9PdRj8/NlrWjdu2tXfuS6K1RZfb22bxCS69n/8TGzfrdfXZtDSS0a2/t2pdEb41qVW8cxgNBEHYgiLrD3lvz9lPatbd27Uuit0a1pLda37MDaJ269+wAWoSwA0HUEnYzu8bM/mJmu83stjp6yGNme8zs9Wwa6lrnp8vm0Bsys52jlp1tZs+b2ZvZ7Zhz7NXUW1tM452YZrzW167u6c9b/p7dzCZI+qukr0kakPSypMXu/qeWNpLDzPZImu3utZ+AYWZflnRI0mPHptYys3skvevuP8v+oZzq7j9qk95W6gSn8a6ot7xpxr+jGl+7Mqc/b0Qde/Y5kna7+1vufljSekkLauij7bn7i5LePW7xAklrs/trNfLH0nI5vbUFdx909+3Z/WFJx6YZr/W1S/TVEnWE/QJJ/xj1eEDtNd+7S/q9mb1iZt11NzOGacem2cpuz6u5n+MVTuPdSsdNM942r10j0583q46wjzU1TTuN/13p7pdL+oak72eHqxif1ZI+r5E5AAcl3VdnM9k04xsl/cDdD9bZy2hj9NWS162OsA9IunDU4+mS9tXQx5jcfV92OyTpGY287Wgn+4/NoJvdDtXcz7+5+353P+LuRyX9QjW+dtk04xslrXP3p7PFtb92Y/XVqtetjrC/LGmGmX3OzCZKWiRpcw19fIKZnZV9cCIzO0vS19V+U1FvlrQku79E0qYae/mYdpnGO2+acdX82tU+/bm7t/xH0nyNfCL/N0k/qaOHnL7+Q9Ifs5836u5N0hMaOaz7l0aOiL4n6RxJWyW9md2e3Ua9/UojU3u/ppFgddTU25c08tbwNUk7sp/5db92ib5a8rpxuiwQBGfQAUEQdiAIwg4EQdiBIAg7EARhB4Ig7EAQ/w8+sGPVrnT8WgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "image, label = dataset[1]\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "print(\"Label:\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "dataset = MNIST(root=\"data/\", train=True, transform=transforms.ToTensor())\n",
    "ten, lab = dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0039, 0.6039, 0.9922, 0.3529, 0.0000],\n",
      "         [0.0000, 0.5451, 0.9922, 0.7451, 0.0078],\n",
      "         [0.0000, 0.0431, 0.7451, 0.9922, 0.2745],\n",
      "         [0.0000, 0.0000, 0.1373, 0.9451, 0.8824],\n",
      "         [0.0000, 0.0000, 0.0000, 0.3176, 0.9412]]])\n"
     ]
    }
   ],
   "source": [
    "#Print the pixels at the 10th to 15th y axis \n",
    "print(ten[:,10:15, 10:15])\n",
    "#1 represents white, and 0 represents black - the some of these values are just in between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12f3de128>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(ten[0,10:15,10:15], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split set into 3 models - training set, validation set, test set\n",
    "#training set - used to train the model , compute the loss, adjust the weights \n",
    "#validation set - evaluate the model while training, adjust parameters like the learning rate, and pick the best model\n",
    "#test set - used to compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def split_indices(n, val_pct):\n",
    "    #split the val into a training dataset and a validation dataset\n",
    "    n_val = int(val_pct*n)\n",
    "    \n",
    "    #random images for the validation set and for the training dataset \n",
    "    idxs = np.random.permutation(n)\n",
    "    \n",
    "    #returns the first n_vals in a tuple, so basically a fraction of the entire dataset, and splits the rest for\n",
    "    #the training set\n",
    "    return idxs[n_val:], idxs[:n_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, val_indices = split_indices(len(dataset), 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomize the data in order to remove bias\n",
    "\n",
    "#sample randomly from indices\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = 100\n",
    "\n",
    "#randomize the data samples\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "train_loader= DataLoader(dataset, batches, sampler=train_sampler)\n",
    "\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "val_loader = DataLoader(dataset, batches, sampler=val_sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model\n",
    "\n",
    "#The logistic regression model is very similar to the linear regression model\n",
    "\n",
    "#there are weights and there are biases - output is obtained by using matrix operations\n",
    "\n",
    "#we can use nn.Linear to crreate the model - and flattened to a vector of size 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "#the output of each image is a vector of size 10, with each element of the vector signifying the probability of \n",
    "#a particular target label - 0 to 9\n",
    "\n",
    "input_size = 28*28 #flatten the image\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "# model = nn.Linear(input_size, num_classes)\n",
    "\n",
    "#super similar to the linear regression model - but this time the inputs and the outputs are way more\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for imgs, labels in train_loader:\n",
    "#     print(labels)\n",
    "#     print(imgs.shape)\n",
    "#     outputs = model(imgs)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10]) tensor([[ 0.2279,  0.0370, -0.3274,  0.0015,  0.0403,  0.0059, -0.1457,  0.1277,\n",
      "         -0.1337,  0.1332]])\n"
     ]
    }
   ],
   "source": [
    "#Since the linear method is expecting a vector, we can't just pass in a tensor that has 3 dimensions, \n",
    "#we need to flatten it out - we can do this by creating a model class that inherists from the nn.module class\n",
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        #putting -1 allows us to use any batch size\n",
    "        xb=xb.reshape(-1,784)\n",
    "        out = self.linear(xb)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "model = MnistModel()\n",
    "\n",
    "for images, labels in train_loader:\n",
    "    outputs = model(images)\n",
    "    break\n",
    "    \n",
    "print(outputs.shape, outputs[:1].data) \n",
    "\n",
    "\n",
    "#the outputs are the random result of passing in the images into the model. However, we need them to represent\n",
    "#a probability, which is between 1 and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax function\n",
    "#probability is boosted up, tries to push it towards one output\n",
    "#divide by sum to end up with probabilities\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1246, 0.1029, 0.0715, 0.0993, 0.1033, 0.0998, 0.0857, 0.1127, 0.0868,\n",
      "         0.1133],\n",
      "        [0.1168, 0.0996, 0.0713, 0.1067, 0.0905, 0.1050, 0.1084, 0.1020, 0.0926,\n",
      "         0.1070],\n",
      "        [0.0934, 0.1019, 0.1037, 0.0884, 0.1108, 0.0873, 0.1139, 0.0912, 0.1203,\n",
      "         0.0892],\n",
      "        [0.0920, 0.0886, 0.0694, 0.1061, 0.0976, 0.1255, 0.1091, 0.1168, 0.0929,\n",
      "         0.1020],\n",
      "        [0.1245, 0.0894, 0.0910, 0.0775, 0.1023, 0.1082, 0.1214, 0.0743, 0.1088,\n",
      "         0.1026],\n",
      "        [0.1299, 0.0804, 0.1178, 0.0941, 0.1129, 0.0997, 0.0899, 0.0806, 0.1000,\n",
      "         0.0945],\n",
      "        [0.1194, 0.0844, 0.0867, 0.0937, 0.1187, 0.0959, 0.1059, 0.0769, 0.1265,\n",
      "         0.0920],\n",
      "        [0.1323, 0.0842, 0.0559, 0.1014, 0.0976, 0.1261, 0.1124, 0.0837, 0.0853,\n",
      "         0.1211],\n",
      "        [0.1256, 0.0826, 0.0676, 0.1052, 0.1016, 0.1051, 0.1131, 0.0941, 0.0995,\n",
      "         0.1055],\n",
      "        [0.1386, 0.1061, 0.0661, 0.0950, 0.1014, 0.0939, 0.1020, 0.0885, 0.0966,\n",
      "         0.1118],\n",
      "        [0.0987, 0.0993, 0.0906, 0.1084, 0.0983, 0.1007, 0.0991, 0.0896, 0.0902,\n",
      "         0.1252],\n",
      "        [0.1174, 0.0753, 0.0604, 0.1102, 0.1021, 0.0959, 0.1150, 0.0953, 0.1230,\n",
      "         0.1055],\n",
      "        [0.1090, 0.0979, 0.0902, 0.0973, 0.1217, 0.1061, 0.1078, 0.0902, 0.0889,\n",
      "         0.0909],\n",
      "        [0.1261, 0.0687, 0.0914, 0.1209, 0.1006, 0.1005, 0.0823, 0.0962, 0.0929,\n",
      "         0.1204],\n",
      "        [0.1066, 0.0785, 0.0766, 0.1389, 0.0698, 0.1345, 0.1070, 0.1020, 0.1008,\n",
      "         0.0854],\n",
      "        [0.1158, 0.1052, 0.0868, 0.0996, 0.0974, 0.1034, 0.0996, 0.1058, 0.0910,\n",
      "         0.0954],\n",
      "        [0.1325, 0.0907, 0.0672, 0.0909, 0.0929, 0.0988, 0.1034, 0.1205, 0.1127,\n",
      "         0.0903],\n",
      "        [0.1022, 0.0919, 0.0690, 0.0977, 0.1074, 0.0959, 0.1299, 0.0739, 0.1426,\n",
      "         0.0895],\n",
      "        [0.1535, 0.0899, 0.0610, 0.0869, 0.0937, 0.1027, 0.1092, 0.0953, 0.1093,\n",
      "         0.0985],\n",
      "        [0.1068, 0.0993, 0.0749, 0.1087, 0.0849, 0.1304, 0.1057, 0.0987, 0.1046,\n",
      "         0.0860],\n",
      "        [0.1031, 0.1060, 0.0801, 0.0976, 0.0960, 0.1029, 0.0959, 0.1160, 0.0925,\n",
      "         0.1100],\n",
      "        [0.1359, 0.0912, 0.0739, 0.1057, 0.1023, 0.1173, 0.0936, 0.0852, 0.0949,\n",
      "         0.1001],\n",
      "        [0.1182, 0.0827, 0.0880, 0.1190, 0.0780, 0.1096, 0.1086, 0.1031, 0.0989,\n",
      "         0.0941],\n",
      "        [0.0968, 0.0973, 0.0825, 0.1134, 0.1035, 0.1139, 0.0866, 0.0899, 0.0964,\n",
      "         0.1198],\n",
      "        [0.1124, 0.0784, 0.0684, 0.0931, 0.1074, 0.1126, 0.1261, 0.0813, 0.1183,\n",
      "         0.1020],\n",
      "        [0.1381, 0.0666, 0.0618, 0.1215, 0.0968, 0.1190, 0.1126, 0.1007, 0.0872,\n",
      "         0.0955],\n",
      "        [0.1349, 0.0873, 0.0803, 0.0890, 0.0911, 0.1030, 0.1094, 0.0959, 0.1053,\n",
      "         0.1038],\n",
      "        [0.1278, 0.0962, 0.0653, 0.1092, 0.0915, 0.1120, 0.0955, 0.0906, 0.0997,\n",
      "         0.1122],\n",
      "        [0.1183, 0.0846, 0.1047, 0.0972, 0.0966, 0.0914, 0.0908, 0.1218, 0.0935,\n",
      "         0.1011],\n",
      "        [0.1171, 0.0932, 0.0634, 0.0956, 0.1096, 0.1189, 0.0913, 0.0952, 0.1181,\n",
      "         0.0977],\n",
      "        [0.1244, 0.0809, 0.0795, 0.1035, 0.1146, 0.0949, 0.0967, 0.1319, 0.0889,\n",
      "         0.0848],\n",
      "        [0.1078, 0.0692, 0.0741, 0.1240, 0.1211, 0.0843, 0.1297, 0.0833, 0.1076,\n",
      "         0.0990],\n",
      "        [0.1024, 0.0825, 0.0698, 0.0970, 0.0809, 0.1062, 0.1383, 0.0805, 0.1449,\n",
      "         0.0975],\n",
      "        [0.0941, 0.0805, 0.0576, 0.0944, 0.0900, 0.1147, 0.1232, 0.1269, 0.1318,\n",
      "         0.0869],\n",
      "        [0.0909, 0.1046, 0.0894, 0.0946, 0.0803, 0.1002, 0.1278, 0.1049, 0.1282,\n",
      "         0.0791],\n",
      "        [0.1072, 0.0832, 0.0770, 0.1218, 0.1099, 0.1106, 0.1049, 0.0868, 0.0930,\n",
      "         0.1056],\n",
      "        [0.1184, 0.1009, 0.0813, 0.0880, 0.0972, 0.0920, 0.1148, 0.0798, 0.1215,\n",
      "         0.1062],\n",
      "        [0.1005, 0.0825, 0.0749, 0.1075, 0.0903, 0.1229, 0.1017, 0.1216, 0.1002,\n",
      "         0.0978],\n",
      "        [0.1258, 0.0891, 0.0837, 0.0972, 0.1009, 0.0952, 0.1008, 0.0950, 0.1092,\n",
      "         0.1031],\n",
      "        [0.1109, 0.0787, 0.0554, 0.1044, 0.0931, 0.0867, 0.1357, 0.0829, 0.1587,\n",
      "         0.0936],\n",
      "        [0.1165, 0.0908, 0.0724, 0.1059, 0.0971, 0.0992, 0.1019, 0.1169, 0.1009,\n",
      "         0.0984],\n",
      "        [0.1415, 0.0857, 0.0579, 0.0790, 0.1067, 0.1166, 0.1148, 0.1077, 0.1005,\n",
      "         0.0896],\n",
      "        [0.1109, 0.0892, 0.0669, 0.1186, 0.0800, 0.1202, 0.1046, 0.1070, 0.0918,\n",
      "         0.1107],\n",
      "        [0.1085, 0.0970, 0.0698, 0.0908, 0.0860, 0.1138, 0.0969, 0.1189, 0.1000,\n",
      "         0.1186],\n",
      "        [0.0999, 0.0827, 0.0723, 0.0997, 0.1080, 0.1107, 0.1071, 0.0793, 0.1295,\n",
      "         0.1109],\n",
      "        [0.1305, 0.0864, 0.0716, 0.1042, 0.1105, 0.0982, 0.1080, 0.0715, 0.1201,\n",
      "         0.0989],\n",
      "        [0.1007, 0.1092, 0.0829, 0.1000, 0.0784, 0.1191, 0.1080, 0.1105, 0.0947,\n",
      "         0.0965],\n",
      "        [0.1249, 0.0964, 0.0801, 0.1017, 0.0945, 0.0901, 0.1116, 0.0998, 0.0892,\n",
      "         0.1117],\n",
      "        [0.0930, 0.0984, 0.0675, 0.0946, 0.1010, 0.1109, 0.0992, 0.1268, 0.1055,\n",
      "         0.1032],\n",
      "        [0.1055, 0.0845, 0.0875, 0.1203, 0.1012, 0.1128, 0.0819, 0.1073, 0.1134,\n",
      "         0.0855],\n",
      "        [0.1171, 0.0864, 0.0663, 0.1300, 0.0948, 0.1167, 0.0882, 0.0999, 0.1168,\n",
      "         0.0838],\n",
      "        [0.1055, 0.1064, 0.0891, 0.0868, 0.1081, 0.0998, 0.0928, 0.1141, 0.0992,\n",
      "         0.0982],\n",
      "        [0.1282, 0.0870, 0.0624, 0.1092, 0.0955, 0.0979, 0.1274, 0.0883, 0.1092,\n",
      "         0.0950],\n",
      "        [0.1025, 0.0728, 0.0586, 0.1129, 0.0917, 0.1164, 0.1168, 0.0851, 0.1571,\n",
      "         0.0861],\n",
      "        [0.0925, 0.1206, 0.0840, 0.0851, 0.1083, 0.0975, 0.1076, 0.1130, 0.0885,\n",
      "         0.1029],\n",
      "        [0.1141, 0.0839, 0.0798, 0.0956, 0.0857, 0.1426, 0.1082, 0.0839, 0.1166,\n",
      "         0.0896],\n",
      "        [0.1070, 0.0883, 0.0624, 0.1017, 0.0850, 0.1147, 0.0991, 0.1240, 0.1218,\n",
      "         0.0960],\n",
      "        [0.0867, 0.0920, 0.0742, 0.0923, 0.0846, 0.1185, 0.1360, 0.1156, 0.1127,\n",
      "         0.0873],\n",
      "        [0.1236, 0.0870, 0.0728, 0.0973, 0.1039, 0.1194, 0.1043, 0.0974, 0.1011,\n",
      "         0.0931],\n",
      "        [0.1282, 0.0926, 0.0733, 0.0999, 0.1118, 0.1152, 0.0882, 0.0963, 0.1153,\n",
      "         0.0793],\n",
      "        [0.1090, 0.1056, 0.0829, 0.1047, 0.0977, 0.1046, 0.1002, 0.1099, 0.0883,\n",
      "         0.0971],\n",
      "        [0.1208, 0.0863, 0.0868, 0.1132, 0.1011, 0.0984, 0.0921, 0.0787, 0.1208,\n",
      "         0.1020],\n",
      "        [0.1402, 0.0928, 0.0742, 0.1011, 0.1074, 0.0966, 0.0952, 0.0776, 0.1227,\n",
      "         0.0921],\n",
      "        [0.1170, 0.0872, 0.0718, 0.1103, 0.0968, 0.1108, 0.0991, 0.0914, 0.1072,\n",
      "         0.1084],\n",
      "        [0.0846, 0.0967, 0.1221, 0.1047, 0.1061, 0.0999, 0.1145, 0.0916, 0.0898,\n",
      "         0.0899],\n",
      "        [0.0983, 0.1015, 0.0709, 0.0860, 0.0979, 0.0902, 0.1227, 0.0702, 0.1625,\n",
      "         0.0997],\n",
      "        [0.1136, 0.0812, 0.0789, 0.1064, 0.0722, 0.1226, 0.1401, 0.1091, 0.1015,\n",
      "         0.0745],\n",
      "        [0.1031, 0.1046, 0.0843, 0.0905, 0.0847, 0.1117, 0.0976, 0.1304, 0.1209,\n",
      "         0.0722],\n",
      "        [0.1286, 0.0940, 0.0745, 0.0794, 0.1153, 0.1051, 0.1160, 0.0710, 0.1127,\n",
      "         0.1034],\n",
      "        [0.1181, 0.0852, 0.0754, 0.1291, 0.0842, 0.1098, 0.0996, 0.0783, 0.1161,\n",
      "         0.1043],\n",
      "        [0.1113, 0.0933, 0.0820, 0.1102, 0.0883, 0.1143, 0.0988, 0.0848, 0.1312,\n",
      "         0.0858],\n",
      "        [0.1061, 0.0765, 0.0743, 0.1190, 0.0914, 0.1304, 0.1218, 0.0979, 0.0910,\n",
      "         0.0915],\n",
      "        [0.0933, 0.0998, 0.0778, 0.0982, 0.1015, 0.1047, 0.0991, 0.1450, 0.0994,\n",
      "         0.0812],\n",
      "        [0.1015, 0.0885, 0.0605, 0.0972, 0.0842, 0.1397, 0.1002, 0.1411, 0.0994,\n",
      "         0.0878],\n",
      "        [0.0965, 0.0947, 0.0849, 0.1060, 0.0996, 0.1038, 0.1084, 0.0885, 0.0956,\n",
      "         0.1221],\n",
      "        [0.1129, 0.0928, 0.0852, 0.0923, 0.1170, 0.0993, 0.1244, 0.0892, 0.0858,\n",
      "         0.1011],\n",
      "        [0.1278, 0.0882, 0.0838, 0.0871, 0.1095, 0.1235, 0.0970, 0.0745, 0.1087,\n",
      "         0.0999],\n",
      "        [0.1037, 0.1150, 0.0833, 0.1079, 0.0868, 0.1154, 0.1015, 0.0783, 0.1189,\n",
      "         0.0892],\n",
      "        [0.1076, 0.0772, 0.0760, 0.1159, 0.0877, 0.1243, 0.0970, 0.1111, 0.1111,\n",
      "         0.0921],\n",
      "        [0.1104, 0.1020, 0.0717, 0.0982, 0.0879, 0.1095, 0.0946, 0.1156, 0.1012,\n",
      "         0.1090],\n",
      "        [0.1051, 0.0928, 0.0842, 0.1156, 0.1038, 0.1159, 0.0862, 0.0854, 0.1022,\n",
      "         0.1087],\n",
      "        [0.0992, 0.0944, 0.0922, 0.0867, 0.1110, 0.1003, 0.1247, 0.0765, 0.1163,\n",
      "         0.0988],\n",
      "        [0.0929, 0.0933, 0.0951, 0.1106, 0.1082, 0.0938, 0.0919, 0.0895, 0.1060,\n",
      "         0.1188],\n",
      "        [0.1042, 0.0856, 0.0766, 0.1176, 0.1003, 0.1323, 0.0734, 0.1042, 0.1132,\n",
      "         0.0925],\n",
      "        [0.1027, 0.0911, 0.0914, 0.0966, 0.1071, 0.1229, 0.0889, 0.0901, 0.1110,\n",
      "         0.0982],\n",
      "        [0.0922, 0.0945, 0.0895, 0.0850, 0.0881, 0.0981, 0.1441, 0.0991, 0.1176,\n",
      "         0.0918],\n",
      "        [0.1141, 0.0958, 0.0830, 0.1054, 0.0904, 0.0943, 0.1009, 0.1040, 0.0994,\n",
      "         0.1126],\n",
      "        [0.1097, 0.0882, 0.0665, 0.1071, 0.1130, 0.1342, 0.0951, 0.0992, 0.1020,\n",
      "         0.0850],\n",
      "        [0.0970, 0.0981, 0.0892, 0.1074, 0.0947, 0.1109, 0.0940, 0.0838, 0.0961,\n",
      "         0.1288],\n",
      "        [0.0885, 0.0807, 0.0733, 0.1000, 0.0968, 0.1407, 0.0921, 0.1066, 0.1177,\n",
      "         0.1036],\n",
      "        [0.1149, 0.0864, 0.0870, 0.1163, 0.1034, 0.0880, 0.0999, 0.0871, 0.1322,\n",
      "         0.0848],\n",
      "        [0.1012, 0.0857, 0.0906, 0.0973, 0.1088, 0.1144, 0.0947, 0.1118, 0.1008,\n",
      "         0.0950],\n",
      "        [0.1079, 0.1048, 0.0712, 0.1106, 0.1001, 0.1152, 0.1016, 0.0850, 0.1018,\n",
      "         0.1017],\n",
      "        [0.1256, 0.1028, 0.0716, 0.0806, 0.0898, 0.0982, 0.0949, 0.1005, 0.1193,\n",
      "         0.1167],\n",
      "        [0.1037, 0.0863, 0.0906, 0.1197, 0.1051, 0.1049, 0.0940, 0.0803, 0.0971,\n",
      "         0.1185],\n",
      "        [0.0974, 0.1060, 0.0732, 0.0982, 0.0977, 0.1030, 0.1063, 0.0916, 0.1296,\n",
      "         0.0970],\n",
      "        [0.1223, 0.0782, 0.0724, 0.1340, 0.0857, 0.1012, 0.1083, 0.0879, 0.0971,\n",
      "         0.1128],\n",
      "        [0.1015, 0.0892, 0.0715, 0.0899, 0.0930, 0.1216, 0.1107, 0.1260, 0.1125,\n",
      "         0.0843],\n",
      "        [0.1070, 0.1127, 0.0752, 0.0943, 0.0914, 0.1030, 0.1051, 0.1003, 0.0950,\n",
      "         0.1160],\n",
      "        [0.1169, 0.0804, 0.0754, 0.1175, 0.0846, 0.1088, 0.1136, 0.0975, 0.1123,\n",
      "         0.0928]])\n"
     ]
    }
   ],
   "source": [
    "probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "#these sum up to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 8, 5, 0, 0, 8, 0, 0, 0, 9, 8, 4, 0, 3, 0, 0, 8, 0, 5, 7, 0, 3, 9,\n",
      "        6, 0, 0, 0, 7, 5, 7, 6, 8, 8, 8, 3, 8, 5, 0, 8, 7, 0, 5, 7, 8, 0, 5, 0,\n",
      "        7, 3, 3, 7, 0, 8, 1, 5, 7, 6, 0, 0, 7, 8, 0, 0, 2, 8, 6, 7, 0, 3, 8, 5,\n",
      "        7, 7, 9, 6, 0, 8, 5, 7, 5, 6, 9, 5, 5, 6, 0, 5, 9, 5, 8, 5, 5, 0, 3, 8,\n",
      "        3, 7, 9, 3])\n"
     ]
    }
   ],
   "source": [
    "max_probs, preds = torch.max(probs, dim=1)\n",
    "#index of the max probability\n",
    "print(preds)\n",
    "# print(max_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 9, 3, 7, 5, 3, 8, 8, 8, 9, 1, 0, 3, 9, 9, 1, 4, 3, 9, 9, 1, 8, 4, 1,\n",
       "        3, 8, 9, 4, 7, 7, 5, 5, 0, 2, 0, 1, 9, 9, 9, 0, 9, 6, 2, 9, 0, 3, 2, 9,\n",
       "        4, 7, 9, 5, 9, 3, 1, 2, 4, 6, 2, 3, 1, 5, 3, 6, 7, 0, 2, 6, 5, 7, 2, 9,\n",
       "        4, 4, 1, 3, 8, 0, 4, 7, 1, 0, 8, 6, 8, 6, 7, 6, 1, 2, 9, 6, 5, 9, 1, 2,\n",
       "        7, 4, 9, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what the number is in the index\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
